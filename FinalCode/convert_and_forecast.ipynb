{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert product_sales.csv into ForecastedInformation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define policy optimization period for forecasting\n",
    "policy_optimization_period = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"product_sales.csv\")\n",
    "# Drop random columns\n",
    "df = df.drop(columns=[\"Unnamed: 107\", \"94\"])\n",
    "# Melt data and remove strings for week names\n",
    "df = df.melt(id_vars=[\"Scode\", \"Pcode\", \"Price\"], var_name=\"Week\", value_name=\"Quantity Sold\")\n",
    "df[\"Week\"] = df[\"Week\"].str.extract('(\\d+)').astype(int)\n",
    "# Will contain (store, sku) pair\n",
    "all_unique_combos = []\n",
    "stores = df[\"Scode\"].unique()\n",
    "# How many stores do we want to forecast for\n",
    "stores = stores[:1] \n",
    "for store in stores:\n",
    "    holder = df[df[\"Scode\"] == store]\n",
    "    skus = holder[\"Pcode\"].unique()\n",
    "    for sku in skus:\n",
    "        all_unique_combos.append((store, sku))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute forecasts in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parellelize this forecasting for speed\n",
    "@ray.remote\n",
    "def forecast_dates(df, pair):\n",
    "    value_column = df[(df[\"Pcode\"] == pair[1]) & (df[\"Scode\"] == pair[0])].reset_index(drop=True)\n",
    "    value_column = value_column[\"Quantity Sold\"]\n",
    "    start_date = \"2023-01-01\"  # Choose an arbitrary start date\n",
    "    date_range = pd.date_range(start=start_date, periods=len(value_column), freq='W') \n",
    "    data = pd.DataFrame({'ds': date_range, 'y': value_column})\n",
    "    model = Prophet(weekly_seasonality=True, yearly_seasonality=True)\n",
    "    model.fit(data)\n",
    "    future = model.make_future_dataframe(periods=policy_optimization_period, freq='W')\n",
    "    forecast = model.predict(future)\n",
    "    return data, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(log_to_driver=False, ignore_reinit_error=True)\n",
    "ds = ray.data.from_pandas(df).repartition(1)\n",
    "block_refs = ds.get_internal_block_refs()\n",
    "forecast_futures = [\n",
    "    forecast_dates.remote(\n",
    "        block_refs[0],\n",
    "        pair\n",
    "    )\n",
    "    for pair in all_unique_combos\n",
    "]\n",
    "results = ray.get(forecast_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append forecasts to the original array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1df = df[df[\"Scode\"] == \"Store1\"]\n",
    "# start with all info from store1\n",
    "skus = store1df[\"Pcode\"].unique()\n",
    "store = \"Store1\"\n",
    "for i,sku in enumerate(skus):\n",
    "    # SKU info\n",
    "    subset = store1df[(store1df[\"Scode\"] == store) & (store1df[\"Pcode\"] == sku)].iloc[0]\n",
    "    price = subset[\"Price\"]\n",
    "    # Get new week info\n",
    "    curr_df = results[i][1]\n",
    "    new_df = curr_df[104:].reset_index()\n",
    "    new_df = new_df[[\"index\", \"yhat\"]].rename(columns={\"index\": \"Week\", \"yhat\": \"Quantity Sold\"})\n",
    "    new_df[\"Scode\"] = store\n",
    "    new_df[\"Pcode\"] = sku\n",
    "    new_df[\"Price\"] = price\n",
    "    store1df = pd.concat([store1df, new_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take all the data from store 1 and make it a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1df = store1df.drop_duplicates()\n",
    "store1df.to_csv(\"ForecastedInformation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
